{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error, precision_recall_fscore_support\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "#from tensorflow.keras.layers.experimental import preprocessing\n",
    "import tensorflow.keras.preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to load training data from individual files\n",
    "def load_training_data(folder_path, count, authors_to_include=[]):\n",
    "    numbers_list = [num for num in range(1, count+1)]\n",
    "    data_list = []\n",
    "    filename_list = []\n",
    "    iterator = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the filename contains \"aggr\"\n",
    "            if \"aggr\" in filename and \"complete\" not in filename:\n",
    "                num = filename.split(\"_\")[2]\n",
    "                if int(num) in numbers_list:\n",
    "                    if iterator < count:\n",
    "                        iterator += 1\n",
    "                        file_path = os.path.join(folder_path, filename)\n",
    "                        df = pd.read_csv(file_path, encoding='latin-1')\n",
    "                        if authors_to_include:\n",
    "                            df = df[df[\"Author\"].isin(authors_to_include)]\n",
    "                        # Replace NaN values with 0.0\n",
    "                        df.fillna(0.0, inplace=True)\n",
    "                        if df.isnull().values.any():\n",
    "                            print(f\"NaN values found in DataFrame: {filename}\")\n",
    "                            print(df[df.isnull().any(axis=1)])\n",
    "                        data_list.append(df)\n",
    "                        filename_list.append(filename)\n",
    "    return pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Define function to load testing data from a single file\n",
    "def load_testing_data(folder_path, count, count_adder, authors_to_include=[]):\n",
    "    numbers_list = [num for num in range(count_adder+1, count_adder+count+1)]\n",
    "    data_list = []\n",
    "    filename_list = []\n",
    "    iterator = 0\n",
    "    count_iterator = 1\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the filename contains \"aggr\"\n",
    "            num = filename.split(\"_\")[2]\n",
    "            if \"aggr\" in filename and \"complete\" not in filename and int(num) in numbers_list:\n",
    "                count_iterator += 1\n",
    "                if iterator < count:\n",
    "                    iterator += 1\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    df = pd.read_csv(file_path, encoding='latin-1')\n",
    "                    # Replace NaN values with 0.0\n",
    "                    if authors_to_include:\n",
    "                        df = df[df[\"Author\"].isin(authors_to_include)]\n",
    "                    df.fillna(0.0, inplace=True)\n",
    "                    data_list.append(df)\n",
    "                    filename_list.append(filename)\n",
    "    return pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "def create_complete_data(folder_path, authors_to_include=[]):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if \"aggr\" in filename and \"complete\" not in filename:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path, encoding='latin-1')\n",
    "\n",
    "            if authors_to_include:\n",
    "                df = df[df[\"Author\"].isin(authors_to_include)]\n",
    "\n",
    "            df.fillna(0.0, inplace=True)\n",
    "\n",
    "            if df.isnull().values.any():\n",
    "                print(f\"NaN values found in DataFrame: {filename}\")\n",
    "                print(df[df.isnull().any(axis=1)])\n",
    "\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9416666666666667\n",
      "Precision: 0.942416945373467\n",
      "Recall: 0.9416666666666667\n",
      "F1-Score: 0.9416579671700965\n"
     ]
    }
   ],
   "source": [
    "author_folder_path = \"authors_csv\"\n",
    "bible_folder_path = \"Bible_authors_csv\"\n",
    "dc_folder_path = \"DC_authors_csv\"\n",
    "desired_authors = [\"nephi\", \"jacob\", \"moroni\", \"mormon\", \"enos\"]\n",
    "df = create_complete_data(author_folder_path, authors_to_include=desired_authors)\n",
    "bible_df = create_complete_data(bible_folder_path)\n",
    "dc_df = create_complete_data(dc_folder_path)\n",
    "df = pd.concat([df, dc_df], ignore_index=True)\n",
    "df = df.fillna(0)\n",
    "target = df[\"Author\"]\n",
    "features = df.drop(columns=[\"Author\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "hyperparameters = {'bootstrap': True, \n",
    "                    'max_depth': None, \n",
    "                    'min_samples_leaf': 2, \n",
    "                    'min_samples_split': 10, \n",
    "                    'n_estimators': 500}\n",
    "\n",
    "hyperparameters = {'bootstrap': False, 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
    "\n",
    "# Initialize the Random Forest Classifier with the hyperparameters\n",
    "rf_model = RandomForestClassifier(**hyperparameters)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Other options: 'micro', 'macro'\n",
    "recall = recall_score(y_test, y_pred, average='weighted')  # Other options: 'micro', 'macro'\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Other options: 'micro', 'macro'\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# desired_author_labels = [np.where(class_names == author)[0][0] for author in desired_authors]\n",
    "\n",
    "# # Step 2: Filter the predictions and true labels\n",
    "# mask = np.isin(y_test, desired_author_labels)\n",
    "# filtered_y_test = y_test[mask]\n",
    "# filtered_predicted_labels = y_pred.argmax(axis=1)[mask]\n",
    "\n",
    "# # Step 3: Calculate accuracy for the filtered data\n",
    "# filtered_accuracy = accuracy_score(filtered_y_test, filtered_predicted_labels)\n",
    "\n",
    "# # Step 4: Calculate precision, recall, F1-score, and support for the filtered data\n",
    "# filtered_precision, filtered_recall, filtered_f1_score, filtered_support = precision_recall_fscore_support(\n",
    "#     filtered_y_test, filtered_predicted_labels, labels=desired_author_labels, average='weighted')\n",
    "\n",
    "# print(\"Filtered Metrics for Desired Authors:\")\n",
    "# print(\"Accuracy:\", filtered_accuracy)\n",
    "# print(\"Precision:\", filtered_precision)\n",
    "# print(\"Recall:\", filtered_recall)\n",
    "# print(\"F1 Score:\", filtered_f1_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.56521739 0.57971014 0.56521739 0.44927536 0.53623188 0.5942029\n",
      " 0.52173913 0.55072464 0.50724638 0.65217391 0.60869565 0.57971014\n",
      " 0.55072464 0.63768116 0.62318841 0.60869565 0.57971014 0.55072464\n",
      " 0.56521739 0.52173913 0.57971014 0.60869565 0.56521739 0.55072464\n",
      " 0.53623188 0.53623188 0.53623188 0.50724638 0.55072464 0.53623188\n",
      " 0.50724638 0.49275362 0.57971014 0.50724638 0.56521739 0.52173913\n",
      " 0.55072464 0.52173913 0.46376812 0.57971014 0.64705882 0.57352941\n",
      " 0.51470588 0.51470588 0.54411765 0.45588235 0.54411765 0.52941176\n",
      " 0.57352941 0.61764706]\n",
      "Mean CV score: 0.5531926683716964\n",
      "Standard deviation of CV scores: 0.04493993177930593\n",
      "                       Feature  Importance\n",
      "316           Total_Word_Count    0.061381\n",
      "317  Total_Function_Word_Count    0.055288\n",
      "319         AVG_Word_Per_Verse    0.030972\n",
      "318        AVG_Letter_Per_Word    0.011369\n",
      "288           a_percentage_use    0.011310\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=50)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "print(\"Mean CV score:\", np.mean(cv_scores))\n",
    "print(\"Standard deviation of CV scores:\", np.std(cv_scores))\n",
    "\n",
    "feature_importances = rf_model.feature_importances_\n",
    "importances_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "importances_df_top5 = importances_df.head(5)\n",
    "print(importances_df_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "Best Model: RandomForestClassifier(bootstrap=False, max_depth=100, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [250, 500],\n",
    "    'max_depth': [5, 15,100, None],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [2, 5, 7, 10, 15],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Model:\", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_path = \"authors_csv\"\n",
    "desired_authors = [\"nephi\", \"jacob\", \"moroni\", \"mormon\", \"enos\"]\n",
    "# Load the training data\n",
    "X_train = load_training_data(\"authors_csv\", 90, desired_authors)\n",
    "#X_train.fillna(0.0, inplace=True)\n",
    "#print(X_train)\n",
    "X_train = shuffle(X_train)\n",
    "# Splitting data into features and target variable\n",
    "y_train = X_train[\"Author\"]\n",
    "X_train = X_train.drop(columns=[\"Author\", \"Total_Word_Count\", 'Total_Function_Word_Count'])\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "test_folder_path = \"authors_csv\"\n",
    "desired_authors = [\"nephi\", \"jacob\", \"moroni\", \"mormon\", \"enos\"]\n",
    "X_test = load_testing_data(test_folder_path, 4, 45, desired_authors)\n",
    "#X_test.fillna(0.0, inplace=True)\n",
    "X_test = shuffle(X_test)\n",
    "# Step 2: Preprocess testing data (drop columns not used in training)\n",
    "X_test_processed = X_test.drop(columns=[\"Author\", \"Total_Word_Count\", \"Total_Function_Word_Count\"])\n",
    "\n",
    "# Step 3: Make predictions using the trained model\n",
    "predictions = knn.predict(X_test_processed)\n",
    "#y_true = X_test[\"Author\"]\n",
    "# Optional: Print the predictions\n",
    "#print(predictions)\n",
    "y_true = X_test[\"Author\"]\n",
    "#print(y_true)\n",
    "print(predictions)\n",
    "accuracy = accuracy_score(y_true, predictions)\n",
    "precision = precision_score(y_true, predictions, average='weighted')  # Other options: 'micro', 'macro'\n",
    "recall = recall_score(y_true, predictions, average='weighted')  # Other options: 'micro', 'macro'\n",
    "f1 = f1_score(y_true, predictions, average='weighted')  # Other options: 'micro', 'macro'\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, num_authors):\n",
    "  features_in_data = X_train.shape[1]\n",
    "  model = Sequential()\n",
    "  model.add(Dense(features_in_data, input_dim=features_in_data, activation='relu'))\n",
    "  model.add(Dropout(0.2))\n",
    "  #model.add(Dense(10, activation='relu'))\n",
    "  model.add(Dense(1024, activation='relu'))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(512, activation='relu'))\n",
    "  model.add(Dropout(0.2))\n",
    "  # model.add(Dense(256, activation='relu'))\n",
    "  # model.add(Dropout(0.2))\n",
    "  # model.add(Dense(128, activation='relu'))\n",
    "  # model.add(Dropout(0.4))\n",
    "  # model.add(Dense(128, activation='relu'))\n",
    "  #model.add(Dropout(0.2))\n",
    "  # model.add(Dense(526, activation = 'relu'))\n",
    "  # #model.add(Dropout(0.2))\n",
    "  model.add(Dense(num_authors, activation = 'softmax'))\n",
    "  #custom_learning_rate = 0.001\n",
    "  custom_learning_rate = 0.01\n",
    "  optimizer = Adam(learning_rate=custom_learning_rate)\n",
    "  model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer, metrics = ['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder_path = \"authors_csv\"\n",
    "desired_authors = [\"nephi\", \"jacob\", \"moroni\", \"mormon\", \"enos\"]\n",
    "df = create_complete_data(test_folder_path, authors_to_include=desired_authors)\n",
    "\n",
    "bible_df = create_complete_data(bible_folder_path)\n",
    "dc_df = create_complete_data(dc_folder_path)\n",
    "df = pd.concat([df, dc_df], ignore_index=True)\n",
    "df = df.fillna(0)\n",
    "\n",
    "\n",
    "features = df.drop(columns=['Author'])\n",
    "target = df['Author']\n",
    "minMaxScaler = MinMaxScaler()\n",
    "features_scaled = pd.DataFrame(minMaxScaler.fit_transform(features), columns=features.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.20, random_state=42)\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2261 - loss: 1.7186 - val_accuracy: 0.5764 - val_loss: 1.5571\n",
      "Epoch 2/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5634 - loss: 1.4745 - val_accuracy: 0.7014 - val_loss: 1.2445\n",
      "Epoch 3/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7617 - loss: 1.0966 - val_accuracy: 0.7708 - val_loss: 0.9430\n",
      "Epoch 4/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8407 - loss: 0.7600 - val_accuracy: 0.8125 - val_loss: 0.7734\n",
      "Epoch 5/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9058 - loss: 0.5436 - val_accuracy: 0.8125 - val_loss: 0.6823\n",
      "Epoch 6/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9446 - loss: 0.3620 - val_accuracy: 0.8611 - val_loss: 0.5446\n",
      "Epoch 7/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9521 - loss: 0.2178 - val_accuracy: 0.8264 - val_loss: 0.6008\n",
      "Epoch 8/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9558 - loss: 0.1550 - val_accuracy: 0.8333 - val_loss: 0.5930\n",
      "Epoch 9/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9742 - loss: 0.0869 - val_accuracy: 0.8056 - val_loss: 0.5849\n",
      "Epoch 10/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9783 - loss: 0.0657 - val_accuracy: 0.7986 - val_loss: 0.8353\n",
      "Epoch 11/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9707 - loss: 0.0812 - val_accuracy: 0.7986 - val_loss: 0.6169\n",
      "Epoch 12/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0416 - val_accuracy: 0.8125 - val_loss: 0.8602\n",
      "Epoch 13/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0248 - val_accuracy: 0.8403 - val_loss: 0.6689\n",
      "Epoch 14/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 0.8264 - val_loss: 0.8297\n",
      "Epoch 15/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9794 - loss: 0.0377 - val_accuracy: 0.8194 - val_loss: 0.9175\n",
      "Epoch 16/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9657 - loss: 0.0659 - val_accuracy: 0.8125 - val_loss: 0.9686\n",
      "Epoch 17/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9831 - loss: 0.0458 - val_accuracy: 0.8472 - val_loss: 0.7992\n",
      "Epoch 18/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9977 - loss: 0.0178 - val_accuracy: 0.8542 - val_loss: 0.7136\n",
      "Epoch 19/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.8333 - val_loss: 0.7975\n",
      "Epoch 20/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8472 - val_loss: 0.9103\n",
      "Epoch 21/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.8472 - val_loss: 0.7535\n",
      "Epoch 22/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8403 - val_loss: 0.7673\n",
      "Epoch 23/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.8403 - val_loss: 0.8785\n",
      "Epoch 24/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8472 - val_loss: 0.8949\n",
      "Epoch 25/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8542 - val_loss: 0.8366\n",
      "Epoch 26/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8611 - val_loss: 0.8315\n",
      "Epoch 27/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8611 - val_loss: 0.8456\n",
      "Epoch 28/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.7898e-04 - val_accuracy: 0.8611 - val_loss: 0.8753\n",
      "Epoch 29/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.0013e-04 - val_accuracy: 0.8542 - val_loss: 0.8932\n",
      "Epoch 30/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8542 - val_loss: 0.8994\n",
      "Epoch 31/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.5500e-04 - val_accuracy: 0.8472 - val_loss: 0.9128\n",
      "Epoch 32/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8403 - val_loss: 0.8899\n",
      "Epoch 33/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.4497e-04 - val_accuracy: 0.8472 - val_loss: 0.8830\n",
      "Epoch 34/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.2896e-04 - val_accuracy: 0.8542 - val_loss: 0.8945\n",
      "Epoch 35/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.2679e-04 - val_accuracy: 0.8542 - val_loss: 0.9100\n",
      "Epoch 36/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.1883e-04 - val_accuracy: 0.8611 - val_loss: 0.9130\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "num_authors = len(label_encoder.classes_)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model = create_model(X_train, num_authors)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "history = model.fit(X_train, y_train_encoded, epochs=1000, validation_split=0.30, batch_size= 50, callbacks=[early_stop], shuffle=True)\n",
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to Name Mapping:\n",
      "{0: 'Joseph Smith', 1: 'enos', 2: 'jacob', 3: 'mormon', 4: 'moroni', 5: 'nephi'}\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Accuracy: 0.8416666666666667\n",
      "Precision: 0.8443852151746888\n",
      "Recall: 0.8416666666666667\n",
      "F1 Score: 0.8404901960784313\n",
      "Support: None\n",
      "Filtered Metrics for Desired Authors:\n",
      "Accuracy: nan\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class_names = label_encoder.classes_\n",
    "\n",
    "label_to_name = dict(zip(range(len(class_names)), class_names))\n",
    "\n",
    "# Print the mapping dictionary\n",
    "print(\"Label to Name Mapping:\")\n",
    "print(label_to_name)\n",
    "\n",
    "desired_authors = [\"nephi\", \"jacob\", \"moroni\", \"mormon\", \"enos\"]\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "predicted_labels = label_encoder.inverse_transform(y_pred.argmax(axis=1))\n",
    "\n",
    "# Print predicted labels\n",
    "#print(\"Predicted labels:\", predicted_labels)\n",
    "\n",
    "# Step 4: Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "# Step 5: Calculate precision, recall, F1-score, support\n",
    "precision, recall, f1_score_nn, support = precision_recall_fscore_support(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score_nn)\n",
    "print(\"Support:\", support)\n",
    "\n",
    "desired_author_labels = [np.where(class_names == author)[0][0] for author in desired_authors]\n",
    "\n",
    "# Step 2: Filter the predictions and true labels\n",
    "mask = np.isin(y_test, desired_author_labels)\n",
    "filtered_y_test = y_test[mask]\n",
    "filtered_predicted_labels = y_pred.argmax(axis=1)[mask]\n",
    "\n",
    "# Step 3: Calculate accuracy for the filtered data\n",
    "filtered_accuracy = accuracy_score(filtered_y_test, filtered_predicted_labels)\n",
    "\n",
    "# Step 4: Calculate precision, recall, F1-score, and support for the filtered data\n",
    "filtered_precision, filtered_recall, filtered_f1_score, filtered_support = precision_recall_fscore_support(\n",
    "    filtered_y_test, filtered_predicted_labels, labels=desired_author_labels, average='weighted')\n",
    "\n",
    "print(\"Filtered Metrics for Desired Authors:\")\n",
    "print(\"Accuracy:\", filtered_accuracy)\n",
    "print(\"Precision:\", filtered_precision)\n",
    "print(\"Recall:\", filtered_recall)\n",
    "print(\"F1 Score:\", filtered_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xg Boost Regressor Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_author = encoder.fit_transform(df[['Author']])\n",
    "encoded_author_df = pd.DataFrame(encoded_author, columns=encoder.get_feature_names_out(['Author']))\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "minMaxScaler = MinMaxScaler()\n",
    "\n",
    "column_scores = {}\n",
    "for i in numeric_columns:\n",
    "    if i == 'Author':\n",
    "        continue\n",
    "\n",
    "    target_variable = i\n",
    "    features = df.drop(columns=[target_variable])\n",
    "    target = df[target_variable]\n",
    "\n",
    "    features = pd.concat([features.drop(columns=['Author']), encoded_author_df], axis=1)\n",
    "\n",
    "    features_scaled = pd.DataFrame(minMaxScaler.fit_transform(features), columns=features.columns)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, learning_rate=0.005, random_state=42)\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    n = X_test.shape[0]  \n",
    "    p = X_test.shape[1]  \n",
    "    adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "    column_scores[i] = {\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"R-squared\": r2,\n",
    "        \"Adjusted R-squared\": adjusted_r2,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"Mean Absolute Percentage Error\": mape\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "# for column, scores in column_scores.items():\n",
    "#     print(f\"{column}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_values = pd.DataFrame([\n",
    "    {'R-squared': metrics['R-squared']} \n",
    "    for metrics in column_scores.values() \n",
    "    if metrics['R-squared'] >= 0\n",
    "])\n",
    "\n",
    "summary = r_squared_values.describe()\n",
    "\n",
    "# Count values below 0 before clipping\n",
    "values_below_zero = (r_squared_values < 0).sum().sum()\n",
    "\n",
    "# Additional statistics for outliers\n",
    "z_scores = (r_squared_values - r_squared_values.mean()) / r_squared_values.std()\n",
    "outliers = r_squared_values[abs(z_scores) > 3].dropna()\n",
    "\n",
    "# Check for outliers and handle separately if necessary\n",
    "if not outliers.empty:\n",
    "    outliers_list = outliers['R-squared'].tolist()\n",
    "    outliers_summary = pd.DataFrame({'outliers': outliers_list})\n",
    "else:\n",
    "    outliers_summary = pd.DataFrame({'outliers': [None]})\n",
    "\n",
    "# Clip non-numeric values from the summary DataFrame\n",
    "numeric_summary = numeric_summary.clip(lower=0)\n",
    "numeric_summary = summary.select_dtypes(include=[float, int])  # Only select numeric columns\n",
    "\n",
    "# Print the numeric summary\n",
    "# print(\"Numeric Summary:\")\n",
    "# print(numeric_summary)\n",
    "\n",
    "# # Print outliers summary\n",
    "# print(\"\\nOutliers Summary:\")\n",
    "# print(outliers_summary)\n",
    "\n",
    "# # Print count of values below 0\n",
    "# print(f\"\\nCount of values below 0: {values_below_zero}\")\n",
    "\n",
    "print(\"Summary statistics:\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
